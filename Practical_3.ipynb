{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Practical 3A**\n",
        "\n",
        "CLASSFICATION USING DNN"
      ],
      "metadata": {
        "id": "0NNO66uz3KG-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRZuECsD3ErE",
        "outputId": "1fb1a740-60b0-45a9-b349-86487477a41c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  6.   , 148.   ,  72.   , ...,   0.627,  50.   ,   1.   ],\n",
              "       [  1.   ,  85.   ,  66.   , ...,   0.351,  31.   ,   0.   ],\n",
              "       [  8.   , 183.   ,  64.   , ...,   0.672,  32.   ,   1.   ],\n",
              "       ...,\n",
              "       [  5.   , 121.   ,  72.   , ...,   0.245,  30.   ,   0.   ],\n",
              "       [  1.   , 126.   ,  60.   , ...,   0.349,  47.   ,   1.   ],\n",
              "       [  1.   ,  93.   ,  70.   , ...,   0.315,  23.   ,   0.   ]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from numpy import loadtxt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "\n",
        "dataset=loadtxt(\"/content/sample_data/pima-indians-diabetes.csv\",delimiter=',');\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=dataset[:,0:8]\n",
        "Y=dataset[:,8]"
      ],
      "metadata": {
        "id": "435MgyfX4ref"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Xh3g4H943SE",
        "outputId": "a6110dca-ca16-4b67-bad8-84d071ec994b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  6.   , 148.   ,  72.   , ...,  33.6  ,   0.627,  50.   ],\n",
              "       [  1.   ,  85.   ,  66.   , ...,  26.6  ,   0.351,  31.   ],\n",
              "       [  8.   , 183.   ,  64.   , ...,  23.3  ,   0.672,  32.   ],\n",
              "       ...,\n",
              "       [  5.   , 121.   ,  72.   , ...,  26.2  ,   0.245,  30.   ],\n",
              "       [  1.   , 126.   ,  60.   , ...,  30.1  ,   0.349,  47.   ],\n",
              "       [  1.   ,  93.   ,  70.   , ...,  30.4  ,   0.315,  23.   ]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yX19pTNV45Gl",
        "outputId": "5c44b282-6038-4c5a-d381-0566fa08cef1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
              "       1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
              "       0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0.,\n",
              "       0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
              "       1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
              "       1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
              "       1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1.,\n",
              "       1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "       1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
              "       1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
              "       1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
              "       1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
              "       0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
              "       1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
              "       1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
              "       1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
              "       0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "       1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
              "       1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
              "       1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1.,\n",
              "       1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0.,\n",
              "       0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
              "       0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0.,\n",
              "       0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
              "       1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
              "       0., 1., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating model\n",
        "model=Sequential()\n",
        "model.add(Dense(12,input_dim=8,activation='relu'))\n",
        "model.add(Dense(8,activation='relu'))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "#Compiling and fitting model\n",
        "model.compile(loss=\"binary_crossentropy\",optimizer='adam',metrics=['accuracy'])\n",
        "model.fit(X,Y,epochs=150,batch_size=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PflUGqN47Dl",
        "outputId": "cbeab9bb-7d68-4292-afe0-93e8d1b1a85b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "77/77 [==============================] - 1s 1ms/step - loss: 5.2630 - accuracy: 0.3997\n",
            "Epoch 2/150\n",
            "77/77 [==============================] - 0s 919us/step - loss: 1.3363 - accuracy: 0.5143\n",
            "Epoch 3/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.8956 - accuracy: 0.5898\n",
            "Epoch 4/150\n",
            "77/77 [==============================] - 0s 962us/step - loss: 0.7757 - accuracy: 0.6211\n",
            "Epoch 5/150\n",
            "77/77 [==============================] - 0s 975us/step - loss: 0.7109 - accuracy: 0.6380\n",
            "Epoch 6/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6851 - accuracy: 0.6484\n",
            "Epoch 7/150\n",
            "77/77 [==============================] - 0s 986us/step - loss: 0.6646 - accuracy: 0.6484\n",
            "Epoch 8/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6632 - accuracy: 0.6419\n",
            "Epoch 9/150\n",
            "77/77 [==============================] - 0s 979us/step - loss: 0.6517 - accuracy: 0.6628\n",
            "Epoch 10/150\n",
            "77/77 [==============================] - 0s 904us/step - loss: 0.6429 - accuracy: 0.6654\n",
            "Epoch 11/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6343 - accuracy: 0.6706\n",
            "Epoch 12/150\n",
            "77/77 [==============================] - 0s 912us/step - loss: 0.6339 - accuracy: 0.6693\n",
            "Epoch 13/150\n",
            "77/77 [==============================] - 0s 999us/step - loss: 0.6309 - accuracy: 0.6758\n",
            "Epoch 14/150\n",
            "77/77 [==============================] - 0s 974us/step - loss: 0.6251 - accuracy: 0.6771\n",
            "Epoch 15/150\n",
            "77/77 [==============================] - 0s 926us/step - loss: 0.6230 - accuracy: 0.6797\n",
            "Epoch 16/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6223 - accuracy: 0.6771\n",
            "Epoch 17/150\n",
            "77/77 [==============================] - 0s 921us/step - loss: 0.6212 - accuracy: 0.6719\n",
            "Epoch 18/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6172 - accuracy: 0.6732\n",
            "Epoch 19/150\n",
            "77/77 [==============================] - 0s 957us/step - loss: 0.6202 - accuracy: 0.6758\n",
            "Epoch 20/150\n",
            "77/77 [==============================] - 0s 921us/step - loss: 0.6088 - accuracy: 0.6914\n",
            "Epoch 21/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6128 - accuracy: 0.6680\n",
            "Epoch 22/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6036 - accuracy: 0.6654\n",
            "Epoch 23/150\n",
            "77/77 [==============================] - 0s 909us/step - loss: 0.6137 - accuracy: 0.6797\n",
            "Epoch 24/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6118 - accuracy: 0.6927\n",
            "Epoch 25/150\n",
            "77/77 [==============================] - 0s 907us/step - loss: 0.6031 - accuracy: 0.6823\n",
            "Epoch 26/150\n",
            "77/77 [==============================] - 0s 888us/step - loss: 0.6042 - accuracy: 0.6849\n",
            "Epoch 27/150\n",
            "77/77 [==============================] - 0s 905us/step - loss: 0.5957 - accuracy: 0.6849\n",
            "Epoch 28/150\n",
            "77/77 [==============================] - 0s 935us/step - loss: 0.5939 - accuracy: 0.6901\n",
            "Epoch 29/150\n",
            "77/77 [==============================] - 0s 868us/step - loss: 0.5941 - accuracy: 0.6901\n",
            "Epoch 30/150\n",
            "77/77 [==============================] - 0s 893us/step - loss: 0.5992 - accuracy: 0.6823\n",
            "Epoch 31/150\n",
            "77/77 [==============================] - 0s 911us/step - loss: 0.5983 - accuracy: 0.6810\n",
            "Epoch 32/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5885 - accuracy: 0.6888\n",
            "Epoch 33/150\n",
            "77/77 [==============================] - 0s 959us/step - loss: 0.5883 - accuracy: 0.7018\n",
            "Epoch 34/150\n",
            "77/77 [==============================] - 0s 949us/step - loss: 0.5865 - accuracy: 0.6927\n",
            "Epoch 35/150\n",
            "77/77 [==============================] - 0s 900us/step - loss: 0.5867 - accuracy: 0.6979\n",
            "Epoch 36/150\n",
            "77/77 [==============================] - 0s 948us/step - loss: 0.5880 - accuracy: 0.6862\n",
            "Epoch 37/150\n",
            "77/77 [==============================] - 0s 916us/step - loss: 0.5894 - accuracy: 0.6914\n",
            "Epoch 38/150\n",
            "77/77 [==============================] - 0s 894us/step - loss: 0.5766 - accuracy: 0.7031\n",
            "Epoch 39/150\n",
            "77/77 [==============================] - 0s 936us/step - loss: 0.5712 - accuracy: 0.6966\n",
            "Epoch 40/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5824 - accuracy: 0.7005\n",
            "Epoch 41/150\n",
            "77/77 [==============================] - 0s 879us/step - loss: 0.5675 - accuracy: 0.7161\n",
            "Epoch 42/150\n",
            "77/77 [==============================] - 0s 944us/step - loss: 0.5863 - accuracy: 0.7070\n",
            "Epoch 43/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5666 - accuracy: 0.7135\n",
            "Epoch 44/150\n",
            "77/77 [==============================] - 0s 918us/step - loss: 0.5652 - accuracy: 0.7201\n",
            "Epoch 45/150\n",
            "77/77 [==============================] - 0s 910us/step - loss: 0.5687 - accuracy: 0.7109\n",
            "Epoch 46/150\n",
            "77/77 [==============================] - 0s 969us/step - loss: 0.5612 - accuracy: 0.7253\n",
            "Epoch 47/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5636 - accuracy: 0.7266\n",
            "Epoch 48/150\n",
            "77/77 [==============================] - 0s 994us/step - loss: 0.5780 - accuracy: 0.7135\n",
            "Epoch 49/150\n",
            "77/77 [==============================] - 0s 954us/step - loss: 0.5676 - accuracy: 0.7031\n",
            "Epoch 50/150\n",
            "77/77 [==============================] - 0s 967us/step - loss: 0.5565 - accuracy: 0.7266\n",
            "Epoch 51/150\n",
            "77/77 [==============================] - 0s 999us/step - loss: 0.5582 - accuracy: 0.7201\n",
            "Epoch 52/150\n",
            "77/77 [==============================] - 0s 971us/step - loss: 0.5584 - accuracy: 0.7253\n",
            "Epoch 53/150\n",
            "77/77 [==============================] - 0s 959us/step - loss: 0.5525 - accuracy: 0.7279\n",
            "Epoch 54/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5500 - accuracy: 0.7292\n",
            "Epoch 55/150\n",
            "77/77 [==============================] - 0s 938us/step - loss: 0.5558 - accuracy: 0.7070\n",
            "Epoch 56/150\n",
            "77/77 [==============================] - 0s 954us/step - loss: 0.5571 - accuracy: 0.7266\n",
            "Epoch 57/150\n",
            "77/77 [==============================] - 0s 949us/step - loss: 0.5515 - accuracy: 0.7318\n",
            "Epoch 58/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5623 - accuracy: 0.7279\n",
            "Epoch 59/150\n",
            "77/77 [==============================] - 0s 913us/step - loss: 0.5474 - accuracy: 0.7266\n",
            "Epoch 60/150\n",
            "77/77 [==============================] - 0s 952us/step - loss: 0.5466 - accuracy: 0.7201\n",
            "Epoch 61/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5434 - accuracy: 0.7422\n",
            "Epoch 62/150\n",
            "77/77 [==============================] - 0s 969us/step - loss: 0.5452 - accuracy: 0.7305\n",
            "Epoch 63/150\n",
            "77/77 [==============================] - 0s 926us/step - loss: 0.5474 - accuracy: 0.7253\n",
            "Epoch 64/150\n",
            "77/77 [==============================] - 0s 949us/step - loss: 0.5403 - accuracy: 0.7383\n",
            "Epoch 65/150\n",
            "77/77 [==============================] - 0s 995us/step - loss: 0.5431 - accuracy: 0.7370\n",
            "Epoch 66/150\n",
            "77/77 [==============================] - 0s 933us/step - loss: 0.5475 - accuracy: 0.7253\n",
            "Epoch 67/150\n",
            "77/77 [==============================] - 0s 933us/step - loss: 0.5353 - accuracy: 0.7513\n",
            "Epoch 68/150\n",
            "77/77 [==============================] - 0s 968us/step - loss: 0.5379 - accuracy: 0.7370\n",
            "Epoch 69/150\n",
            "77/77 [==============================] - 0s 990us/step - loss: 0.5375 - accuracy: 0.7331\n",
            "Epoch 70/150\n",
            "77/77 [==============================] - 0s 999us/step - loss: 0.5351 - accuracy: 0.7409\n",
            "Epoch 71/150\n",
            "77/77 [==============================] - 0s 924us/step - loss: 0.5368 - accuracy: 0.7409\n",
            "Epoch 72/150\n",
            "77/77 [==============================] - 0s 960us/step - loss: 0.5378 - accuracy: 0.7487\n",
            "Epoch 73/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5377 - accuracy: 0.7370\n",
            "Epoch 74/150\n",
            "77/77 [==============================] - 0s 915us/step - loss: 0.5302 - accuracy: 0.7396\n",
            "Epoch 75/150\n",
            "77/77 [==============================] - 0s 930us/step - loss: 0.5318 - accuracy: 0.7357\n",
            "Epoch 76/150\n",
            "77/77 [==============================] - 0s 987us/step - loss: 0.5339 - accuracy: 0.7370\n",
            "Epoch 77/150\n",
            "77/77 [==============================] - 0s 967us/step - loss: 0.5315 - accuracy: 0.7461\n",
            "Epoch 78/150\n",
            "77/77 [==============================] - 0s 937us/step - loss: 0.5356 - accuracy: 0.7500\n",
            "Epoch 79/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5254 - accuracy: 0.7565\n",
            "Epoch 80/150\n",
            "77/77 [==============================] - 0s 914us/step - loss: 0.5250 - accuracy: 0.7461\n",
            "Epoch 81/150\n",
            "77/77 [==============================] - 0s 988us/step - loss: 0.5253 - accuracy: 0.7500\n",
            "Epoch 82/150\n",
            "77/77 [==============================] - 0s 896us/step - loss: 0.5391 - accuracy: 0.7279\n",
            "Epoch 83/150\n",
            "77/77 [==============================] - 0s 984us/step - loss: 0.5323 - accuracy: 0.7396\n",
            "Epoch 84/150\n",
            "77/77 [==============================] - 0s 919us/step - loss: 0.5265 - accuracy: 0.7487\n",
            "Epoch 85/150\n",
            "77/77 [==============================] - 0s 907us/step - loss: 0.5384 - accuracy: 0.7396\n",
            "Epoch 86/150\n",
            "77/77 [==============================] - 0s 944us/step - loss: 0.5276 - accuracy: 0.7396\n",
            "Epoch 87/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5261 - accuracy: 0.7357\n",
            "Epoch 88/150\n",
            "77/77 [==============================] - 0s 899us/step - loss: 0.5246 - accuracy: 0.7318\n",
            "Epoch 89/150\n",
            "77/77 [==============================] - 0s 936us/step - loss: 0.5244 - accuracy: 0.7448\n",
            "Epoch 90/150\n",
            "77/77 [==============================] - 0s 910us/step - loss: 0.5209 - accuracy: 0.7552\n",
            "Epoch 91/150\n",
            "77/77 [==============================] - 0s 941us/step - loss: 0.5245 - accuracy: 0.7396\n",
            "Epoch 92/150\n",
            "77/77 [==============================] - 0s 894us/step - loss: 0.5220 - accuracy: 0.7448\n",
            "Epoch 93/150\n",
            "77/77 [==============================] - 0s 922us/step - loss: 0.5237 - accuracy: 0.7383\n",
            "Epoch 94/150\n",
            "77/77 [==============================] - 0s 981us/step - loss: 0.5211 - accuracy: 0.7539\n",
            "Epoch 95/150\n",
            "77/77 [==============================] - 0s 998us/step - loss: 0.5163 - accuracy: 0.7565\n",
            "Epoch 96/150\n",
            "77/77 [==============================] - 0s 928us/step - loss: 0.5261 - accuracy: 0.7331\n",
            "Epoch 97/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5191 - accuracy: 0.7578\n",
            "Epoch 98/150\n",
            "77/77 [==============================] - 0s 967us/step - loss: 0.5210 - accuracy: 0.7630\n",
            "Epoch 99/150\n",
            "77/77 [==============================] - 0s 908us/step - loss: 0.5239 - accuracy: 0.7552\n",
            "Epoch 100/150\n",
            "77/77 [==============================] - 0s 906us/step - loss: 0.5202 - accuracy: 0.7461\n",
            "Epoch 101/150\n",
            "77/77 [==============================] - 0s 938us/step - loss: 0.5198 - accuracy: 0.7487\n",
            "Epoch 102/150\n",
            "77/77 [==============================] - 0s 893us/step - loss: 0.5138 - accuracy: 0.7526\n",
            "Epoch 103/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5255 - accuracy: 0.7487\n",
            "Epoch 104/150\n",
            "77/77 [==============================] - 0s 956us/step - loss: 0.5143 - accuracy: 0.7591\n",
            "Epoch 105/150\n",
            "77/77 [==============================] - 0s 997us/step - loss: 0.5153 - accuracy: 0.7422\n",
            "Epoch 106/150\n",
            "77/77 [==============================] - 0s 902us/step - loss: 0.5173 - accuracy: 0.7539\n",
            "Epoch 107/150\n",
            "77/77 [==============================] - 0s 934us/step - loss: 0.5140 - accuracy: 0.7409\n",
            "Epoch 108/150\n",
            "77/77 [==============================] - 0s 998us/step - loss: 0.5145 - accuracy: 0.7604\n",
            "Epoch 109/150\n",
            "77/77 [==============================] - 0s 945us/step - loss: 0.5147 - accuracy: 0.7552\n",
            "Epoch 110/150\n",
            "77/77 [==============================] - 0s 946us/step - loss: 0.5118 - accuracy: 0.7591\n",
            "Epoch 111/150\n",
            "77/77 [==============================] - 0s 942us/step - loss: 0.5128 - accuracy: 0.7500\n",
            "Epoch 112/150\n",
            "77/77 [==============================] - 0s 963us/step - loss: 0.5110 - accuracy: 0.7552\n",
            "Epoch 113/150\n",
            "77/77 [==============================] - 0s 948us/step - loss: 0.5105 - accuracy: 0.7487\n",
            "Epoch 114/150\n",
            "77/77 [==============================] - 0s 911us/step - loss: 0.5096 - accuracy: 0.7604\n",
            "Epoch 115/150\n",
            "77/77 [==============================] - 0s 989us/step - loss: 0.5082 - accuracy: 0.7578\n",
            "Epoch 116/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5102 - accuracy: 0.7552\n",
            "Epoch 117/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5068 - accuracy: 0.7617\n",
            "Epoch 118/150\n",
            "77/77 [==============================] - 0s 989us/step - loss: 0.5076 - accuracy: 0.7604\n",
            "Epoch 119/150\n",
            "77/77 [==============================] - 0s 976us/step - loss: 0.5079 - accuracy: 0.7448\n",
            "Epoch 120/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5082 - accuracy: 0.7760\n",
            "Epoch 121/150\n",
            "77/77 [==============================] - 0s 965us/step - loss: 0.5105 - accuracy: 0.7539\n",
            "Epoch 122/150\n",
            "77/77 [==============================] - 0s 960us/step - loss: 0.5117 - accuracy: 0.7383\n",
            "Epoch 123/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5079 - accuracy: 0.7643\n",
            "Epoch 124/150\n",
            "77/77 [==============================] - 0s 917us/step - loss: 0.5020 - accuracy: 0.7656\n",
            "Epoch 125/150\n",
            "77/77 [==============================] - 0s 993us/step - loss: 0.5049 - accuracy: 0.7461\n",
            "Epoch 126/150\n",
            "77/77 [==============================] - 0s 935us/step - loss: 0.5078 - accuracy: 0.7617\n",
            "Epoch 127/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5054 - accuracy: 0.7617\n",
            "Epoch 128/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5021 - accuracy: 0.7552\n",
            "Epoch 129/150\n",
            "77/77 [==============================] - 0s 931us/step - loss: 0.5110 - accuracy: 0.7474\n",
            "Epoch 130/150\n",
            "77/77 [==============================] - 0s 984us/step - loss: 0.5024 - accuracy: 0.7565\n",
            "Epoch 131/150\n",
            "77/77 [==============================] - 0s 933us/step - loss: 0.5053 - accuracy: 0.7565\n",
            "Epoch 132/150\n",
            "77/77 [==============================] - 0s 953us/step - loss: 0.5010 - accuracy: 0.7578\n",
            "Epoch 133/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5028 - accuracy: 0.7539\n",
            "Epoch 134/150\n",
            "77/77 [==============================] - 0s 922us/step - loss: 0.5066 - accuracy: 0.7578\n",
            "Epoch 135/150\n",
            "77/77 [==============================] - 0s 901us/step - loss: 0.5042 - accuracy: 0.7500\n",
            "Epoch 136/150\n",
            "77/77 [==============================] - 0s 913us/step - loss: 0.5052 - accuracy: 0.7513\n",
            "Epoch 137/150\n",
            "77/77 [==============================] - 0s 987us/step - loss: 0.5000 - accuracy: 0.7591\n",
            "Epoch 138/150\n",
            "77/77 [==============================] - 0s 927us/step - loss: 0.5021 - accuracy: 0.7656\n",
            "Epoch 139/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4964 - accuracy: 0.7682\n",
            "Epoch 140/150\n",
            "77/77 [==============================] - 0s 952us/step - loss: 0.5047 - accuracy: 0.7591\n",
            "Epoch 141/150\n",
            "77/77 [==============================] - 0s 950us/step - loss: 0.4975 - accuracy: 0.7513\n",
            "Epoch 142/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4937 - accuracy: 0.7643\n",
            "Epoch 143/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4979 - accuracy: 0.7565\n",
            "Epoch 144/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4923 - accuracy: 0.7630\n",
            "Epoch 145/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4994 - accuracy: 0.7552\n",
            "Epoch 146/150\n",
            "77/77 [==============================] - 0s 963us/step - loss: 0.5128 - accuracy: 0.7617\n",
            "Epoch 147/150\n",
            "77/77 [==============================] - 0s 951us/step - loss: 0.4986 - accuracy: 0.7435\n",
            "Epoch 148/150\n",
            "77/77 [==============================] - 0s 983us/step - loss: 0.4973 - accuracy: 0.7552\n",
            "Epoch 149/150\n",
            "77/77 [==============================] - 0s 963us/step - loss: 0.4947 - accuracy: 0.7695\n",
            "Epoch 150/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4974 - accuracy: 0.7630\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1f243edad0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X,Y,epochs=150,batch_size=10)\n",
        "predictions=model.predict(X)\n",
        "rounded=[round(x[0])for x in predictions]\n",
        "print(rounded)\n",
        "scores=model.evaluate(X,Y)\n",
        "print(\"\\n%s: %.2f%%\"%(model.metrics_names[1],scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAgXgtzD7Unb",
        "outputId": "c077d5fc-0c3b-4682-8a7c-03d13d9644e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "77/77 [==============================] - 0s 979us/step - loss: 0.4995 - accuracy: 0.7474\n",
            "Epoch 2/150\n",
            "77/77 [==============================] - 0s 993us/step - loss: 0.4931 - accuracy: 0.7500\n",
            "Epoch 3/150\n",
            "77/77 [==============================] - 0s 906us/step - loss: 0.5020 - accuracy: 0.7487\n",
            "Epoch 4/150\n",
            "77/77 [==============================] - 0s 934us/step - loss: 0.4991 - accuracy: 0.7526\n",
            "Epoch 5/150\n",
            "77/77 [==============================] - 0s 942us/step - loss: 0.4948 - accuracy: 0.7565\n",
            "Epoch 6/150\n",
            "77/77 [==============================] - 0s 943us/step - loss: 0.5018 - accuracy: 0.7630\n",
            "Epoch 7/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4990 - accuracy: 0.7604\n",
            "Epoch 8/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4917 - accuracy: 0.7643\n",
            "Epoch 9/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4904 - accuracy: 0.7617\n",
            "Epoch 10/150\n",
            "77/77 [==============================] - 0s 933us/step - loss: 0.4960 - accuracy: 0.7591\n",
            "Epoch 11/150\n",
            "77/77 [==============================] - 0s 976us/step - loss: 0.4881 - accuracy: 0.7682\n",
            "Epoch 12/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4920 - accuracy: 0.7630\n",
            "Epoch 13/150\n",
            "77/77 [==============================] - 0s 926us/step - loss: 0.4885 - accuracy: 0.7721\n",
            "Epoch 14/150\n",
            "77/77 [==============================] - 0s 987us/step - loss: 0.4899 - accuracy: 0.7526\n",
            "Epoch 15/150\n",
            "77/77 [==============================] - 0s 953us/step - loss: 0.4933 - accuracy: 0.7461\n",
            "Epoch 16/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4872 - accuracy: 0.7617\n",
            "Epoch 17/150\n",
            "77/77 [==============================] - 0s 975us/step - loss: 0.4957 - accuracy: 0.7604\n",
            "Epoch 18/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4908 - accuracy: 0.7591\n",
            "Epoch 19/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4986 - accuracy: 0.7643\n",
            "Epoch 20/150\n",
            "77/77 [==============================] - 0s 940us/step - loss: 0.4914 - accuracy: 0.7734\n",
            "Epoch 21/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4915 - accuracy: 0.7643\n",
            "Epoch 22/150\n",
            "77/77 [==============================] - 0s 982us/step - loss: 0.4831 - accuracy: 0.7669\n",
            "Epoch 23/150\n",
            "77/77 [==============================] - 0s 962us/step - loss: 0.4895 - accuracy: 0.7591\n",
            "Epoch 24/150\n",
            "77/77 [==============================] - 0s 946us/step - loss: 0.4914 - accuracy: 0.7474\n",
            "Epoch 25/150\n",
            "77/77 [==============================] - 0s 923us/step - loss: 0.4841 - accuracy: 0.7669\n",
            "Epoch 26/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4871 - accuracy: 0.7630\n",
            "Epoch 27/150\n",
            "77/77 [==============================] - 0s 912us/step - loss: 0.4850 - accuracy: 0.7708\n",
            "Epoch 28/150\n",
            "77/77 [==============================] - 0s 975us/step - loss: 0.4829 - accuracy: 0.7669\n",
            "Epoch 29/150\n",
            "77/77 [==============================] - 0s 991us/step - loss: 0.4865 - accuracy: 0.7539\n",
            "Epoch 30/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4881 - accuracy: 0.7604\n",
            "Epoch 31/150\n",
            "77/77 [==============================] - 0s 956us/step - loss: 0.4934 - accuracy: 0.7643\n",
            "Epoch 32/150\n",
            "77/77 [==============================] - 0s 936us/step - loss: 0.4843 - accuracy: 0.7526\n",
            "Epoch 33/150\n",
            "77/77 [==============================] - 0s 976us/step - loss: 0.4836 - accuracy: 0.7695\n",
            "Epoch 34/150\n",
            "77/77 [==============================] - 0s 941us/step - loss: 0.4803 - accuracy: 0.7669\n",
            "Epoch 35/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4794 - accuracy: 0.7747\n",
            "Epoch 36/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4867 - accuracy: 0.7552\n",
            "Epoch 37/150\n",
            "77/77 [==============================] - 0s 928us/step - loss: 0.4907 - accuracy: 0.7682\n",
            "Epoch 38/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4797 - accuracy: 0.7526\n",
            "Epoch 39/150\n",
            "77/77 [==============================] - 0s 924us/step - loss: 0.4887 - accuracy: 0.7630\n",
            "Epoch 40/150\n",
            "77/77 [==============================] - 0s 915us/step - loss: 0.4916 - accuracy: 0.7656\n",
            "Epoch 41/150\n",
            "77/77 [==============================] - 0s 975us/step - loss: 0.4810 - accuracy: 0.7656\n",
            "Epoch 42/150\n",
            "77/77 [==============================] - 0s 965us/step - loss: 0.4809 - accuracy: 0.7539\n",
            "Epoch 43/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4832 - accuracy: 0.7630\n",
            "Epoch 44/150\n",
            "77/77 [==============================] - 0s 923us/step - loss: 0.4827 - accuracy: 0.7773\n",
            "Epoch 45/150\n",
            "77/77 [==============================] - 0s 961us/step - loss: 0.4862 - accuracy: 0.7630\n",
            "Epoch 46/150\n",
            "77/77 [==============================] - 0s 944us/step - loss: 0.4862 - accuracy: 0.7708\n",
            "Epoch 47/150\n",
            "77/77 [==============================] - 0s 979us/step - loss: 0.4798 - accuracy: 0.7747\n",
            "Epoch 48/150\n",
            "77/77 [==============================] - 0s 956us/step - loss: 0.4823 - accuracy: 0.7695\n",
            "Epoch 49/150\n",
            "77/77 [==============================] - 0s 944us/step - loss: 0.4793 - accuracy: 0.7747\n",
            "Epoch 50/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4753 - accuracy: 0.7669\n",
            "Epoch 51/150\n",
            "77/77 [==============================] - 0s 974us/step - loss: 0.4767 - accuracy: 0.7773\n",
            "Epoch 52/150\n",
            "77/77 [==============================] - 0s 946us/step - loss: 0.4792 - accuracy: 0.7734\n",
            "Epoch 53/150\n",
            "77/77 [==============================] - 0s 971us/step - loss: 0.4779 - accuracy: 0.7643\n",
            "Epoch 54/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4833 - accuracy: 0.7669\n",
            "Epoch 55/150\n",
            "77/77 [==============================] - 0s 953us/step - loss: 0.4768 - accuracy: 0.7708\n",
            "Epoch 56/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4812 - accuracy: 0.7500\n",
            "Epoch 57/150\n",
            "77/77 [==============================] - 0s 953us/step - loss: 0.4784 - accuracy: 0.7539\n",
            "Epoch 58/150\n",
            "77/77 [==============================] - 0s 944us/step - loss: 0.4746 - accuracy: 0.7669\n",
            "Epoch 59/150\n",
            "77/77 [==============================] - 0s 965us/step - loss: 0.4806 - accuracy: 0.7643\n",
            "Epoch 60/150\n",
            "77/77 [==============================] - 0s 922us/step - loss: 0.4827 - accuracy: 0.7578\n",
            "Epoch 61/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4816 - accuracy: 0.7643\n",
            "Epoch 62/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4827 - accuracy: 0.7773\n",
            "Epoch 63/150\n",
            "77/77 [==============================] - 0s 985us/step - loss: 0.4803 - accuracy: 0.7604\n",
            "Epoch 64/150\n",
            "77/77 [==============================] - 0s 950us/step - loss: 0.4753 - accuracy: 0.7721\n",
            "Epoch 65/150\n",
            "77/77 [==============================] - 0s 998us/step - loss: 0.4831 - accuracy: 0.7591\n",
            "Epoch 66/150\n",
            "77/77 [==============================] - 0s 966us/step - loss: 0.4760 - accuracy: 0.7708\n",
            "Epoch 67/150\n",
            "77/77 [==============================] - 0s 966us/step - loss: 0.4757 - accuracy: 0.7682\n",
            "Epoch 68/150\n",
            "77/77 [==============================] - 0s 997us/step - loss: 0.4772 - accuracy: 0.7708\n",
            "Epoch 69/150\n",
            "77/77 [==============================] - 0s 980us/step - loss: 0.4739 - accuracy: 0.7591\n",
            "Epoch 70/150\n",
            "77/77 [==============================] - 0s 970us/step - loss: 0.4941 - accuracy: 0.7487\n",
            "Epoch 71/150\n",
            "77/77 [==============================] - 0s 960us/step - loss: 0.4840 - accuracy: 0.7591\n",
            "Epoch 72/150\n",
            "77/77 [==============================] - 0s 964us/step - loss: 0.4711 - accuracy: 0.7630\n",
            "Epoch 73/150\n",
            "77/77 [==============================] - 0s 958us/step - loss: 0.4795 - accuracy: 0.7591\n",
            "Epoch 74/150\n",
            "77/77 [==============================] - 0s 921us/step - loss: 0.4741 - accuracy: 0.7786\n",
            "Epoch 75/150\n",
            "77/77 [==============================] - 0s 997us/step - loss: 0.4725 - accuracy: 0.7721\n",
            "Epoch 76/150\n",
            "77/77 [==============================] - 0s 979us/step - loss: 0.4757 - accuracy: 0.7604\n",
            "Epoch 77/150\n",
            "77/77 [==============================] - 0s 925us/step - loss: 0.4761 - accuracy: 0.7682\n",
            "Epoch 78/150\n",
            "77/77 [==============================] - 0s 928us/step - loss: 0.4758 - accuracy: 0.7578\n",
            "Epoch 79/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4682 - accuracy: 0.7708\n",
            "Epoch 80/150\n",
            "77/77 [==============================] - 0s 935us/step - loss: 0.4725 - accuracy: 0.7552\n",
            "Epoch 81/150\n",
            "77/77 [==============================] - 0s 942us/step - loss: 0.4742 - accuracy: 0.7617\n",
            "Epoch 82/150\n",
            "77/77 [==============================] - 0s 954us/step - loss: 0.4692 - accuracy: 0.7734\n",
            "Epoch 83/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4828 - accuracy: 0.7539\n",
            "Epoch 84/150\n",
            "77/77 [==============================] - 0s 944us/step - loss: 0.4714 - accuracy: 0.7708\n",
            "Epoch 85/150\n",
            "77/77 [==============================] - 0s 943us/step - loss: 0.4743 - accuracy: 0.7656\n",
            "Epoch 86/150\n",
            "77/77 [==============================] - 0s 916us/step - loss: 0.4731 - accuracy: 0.7682\n",
            "Epoch 87/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4781 - accuracy: 0.7708\n",
            "Epoch 88/150\n",
            "77/77 [==============================] - 0s 918us/step - loss: 0.4668 - accuracy: 0.7708\n",
            "Epoch 89/150\n",
            "77/77 [==============================] - 0s 972us/step - loss: 0.4764 - accuracy: 0.7799\n",
            "Epoch 90/150\n",
            "77/77 [==============================] - 0s 984us/step - loss: 0.4753 - accuracy: 0.7695\n",
            "Epoch 91/150\n",
            "77/77 [==============================] - 0s 956us/step - loss: 0.4687 - accuracy: 0.7865\n",
            "Epoch 92/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4648 - accuracy: 0.7839\n",
            "Epoch 93/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4723 - accuracy: 0.7604\n",
            "Epoch 94/150\n",
            "77/77 [==============================] - 0s 947us/step - loss: 0.4705 - accuracy: 0.7695\n",
            "Epoch 95/150\n",
            "77/77 [==============================] - 0s 971us/step - loss: 0.4676 - accuracy: 0.7734\n",
            "Epoch 96/150\n",
            "77/77 [==============================] - 0s 985us/step - loss: 0.4689 - accuracy: 0.7682\n",
            "Epoch 97/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4644 - accuracy: 0.7812\n",
            "Epoch 98/150\n",
            "77/77 [==============================] - 0s 992us/step - loss: 0.4698 - accuracy: 0.7799\n",
            "Epoch 99/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4723 - accuracy: 0.7643\n",
            "Epoch 100/150\n",
            "77/77 [==============================] - 0s 968us/step - loss: 0.4724 - accuracy: 0.7708\n",
            "Epoch 101/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4715 - accuracy: 0.7617\n",
            "Epoch 102/150\n",
            "77/77 [==============================] - 0s 992us/step - loss: 0.4587 - accuracy: 0.7656\n",
            "Epoch 103/150\n",
            "77/77 [==============================] - 0s 969us/step - loss: 0.4701 - accuracy: 0.7695\n",
            "Epoch 104/150\n",
            "77/77 [==============================] - 0s 999us/step - loss: 0.4746 - accuracy: 0.7578\n",
            "Epoch 105/150\n",
            "77/77 [==============================] - 0s 974us/step - loss: 0.4790 - accuracy: 0.7630\n",
            "Epoch 106/150\n",
            "77/77 [==============================] - 0s 958us/step - loss: 0.4757 - accuracy: 0.7591\n",
            "Epoch 107/150\n",
            "77/77 [==============================] - 0s 932us/step - loss: 0.4721 - accuracy: 0.7539\n",
            "Epoch 108/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4682 - accuracy: 0.7656\n",
            "Epoch 109/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4625 - accuracy: 0.7721\n",
            "Epoch 110/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4766 - accuracy: 0.7682\n",
            "Epoch 111/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4685 - accuracy: 0.7812\n",
            "Epoch 112/150\n",
            "77/77 [==============================] - 0s 954us/step - loss: 0.4660 - accuracy: 0.7695\n",
            "Epoch 113/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4609 - accuracy: 0.7708\n",
            "Epoch 114/150\n",
            "77/77 [==============================] - 0s 990us/step - loss: 0.4654 - accuracy: 0.7839\n",
            "Epoch 115/150\n",
            "77/77 [==============================] - 0s 991us/step - loss: 0.4640 - accuracy: 0.7773\n",
            "Epoch 116/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4604 - accuracy: 0.7721\n",
            "Epoch 117/150\n",
            "77/77 [==============================] - 0s 979us/step - loss: 0.4755 - accuracy: 0.7617\n",
            "Epoch 118/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4687 - accuracy: 0.7669\n",
            "Epoch 119/150\n",
            "77/77 [==============================] - 0s 968us/step - loss: 0.4636 - accuracy: 0.7721\n",
            "Epoch 120/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4594 - accuracy: 0.7852\n",
            "Epoch 121/150\n",
            "77/77 [==============================] - 0s 952us/step - loss: 0.4667 - accuracy: 0.7630\n",
            "Epoch 122/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4659 - accuracy: 0.7669\n",
            "Epoch 123/150\n",
            "77/77 [==============================] - 0s 938us/step - loss: 0.4587 - accuracy: 0.7760\n",
            "Epoch 124/150\n",
            "77/77 [==============================] - 0s 947us/step - loss: 0.4630 - accuracy: 0.7734\n",
            "Epoch 125/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4647 - accuracy: 0.7760\n",
            "Epoch 126/150\n",
            "77/77 [==============================] - 0s 978us/step - loss: 0.4597 - accuracy: 0.7734\n",
            "Epoch 127/150\n",
            "77/77 [==============================] - 0s 968us/step - loss: 0.4586 - accuracy: 0.7682\n",
            "Epoch 128/150\n",
            "77/77 [==============================] - 0s 976us/step - loss: 0.4630 - accuracy: 0.7695\n",
            "Epoch 129/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4650 - accuracy: 0.7747\n",
            "Epoch 130/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4625 - accuracy: 0.7682\n",
            "Epoch 131/150\n",
            "77/77 [==============================] - 0s 948us/step - loss: 0.4635 - accuracy: 0.7747\n",
            "Epoch 132/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4638 - accuracy: 0.7799\n",
            "Epoch 133/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4578 - accuracy: 0.7760\n",
            "Epoch 134/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4715 - accuracy: 0.7904\n",
            "Epoch 135/150\n",
            "77/77 [==============================] - 0s 986us/step - loss: 0.4664 - accuracy: 0.7708\n",
            "Epoch 136/150\n",
            "77/77 [==============================] - 0s 944us/step - loss: 0.4600 - accuracy: 0.7656\n",
            "Epoch 137/150\n",
            "77/77 [==============================] - 0s 978us/step - loss: 0.4562 - accuracy: 0.7812\n",
            "Epoch 138/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4731 - accuracy: 0.7695\n",
            "Epoch 139/150\n",
            "77/77 [==============================] - 0s 984us/step - loss: 0.4587 - accuracy: 0.7747\n",
            "Epoch 140/150\n",
            "77/77 [==============================] - 0s 985us/step - loss: 0.4583 - accuracy: 0.7799\n",
            "Epoch 141/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4652 - accuracy: 0.7695\n",
            "Epoch 142/150\n",
            "77/77 [==============================] - 0s 993us/step - loss: 0.4671 - accuracy: 0.7812\n",
            "Epoch 143/150\n",
            "77/77 [==============================] - 0s 960us/step - loss: 0.4618 - accuracy: 0.7656\n",
            "Epoch 144/150\n",
            "77/77 [==============================] - 0s 986us/step - loss: 0.4636 - accuracy: 0.7682\n",
            "Epoch 145/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4541 - accuracy: 0.7786\n",
            "Epoch 146/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4558 - accuracy: 0.7734\n",
            "Epoch 147/150\n",
            "77/77 [==============================] - 0s 991us/step - loss: 0.4637 - accuracy: 0.7669\n",
            "Epoch 148/150\n",
            "77/77 [==============================] - 0s 973us/step - loss: 0.4599 - accuracy: 0.7695\n",
            "Epoch 149/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4543 - accuracy: 0.7852\n",
            "Epoch 150/150\n",
            "77/77 [==============================] - 0s 981us/step - loss: 0.4605 - accuracy: 0.7773\n",
            "[1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0]\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.4480 - accuracy: 0.7917\n",
            "\n",
            "accuracy: 79.17%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Practical 3B**\n",
        "**BINARY CLASSIFICATION USING MLP**\n"
      ],
      "metadata": {
        "id": "AZZGDaKrdX7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mlp for binary classification\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "# load the dataset\n",
        "path = '/content/sample_data/ionosphere.csv'\n",
        "df = read_csv(path, header=None)\n",
        "# split into input and output columns\n",
        "X, y = df.values[:, :-1], df.values[:, -1]\n",
        "# ensure all data are floating point values\n",
        "X = X.astype('float32')\n",
        "# encode strings to integer\n",
        "y = LabelEncoder().fit_transform(y)\n",
        "# split into train and test datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
        "# determine the number of input features\n",
        "n_features = X_train.shape[1]\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
        "model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# fit the model\n",
        "model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=0)\n",
        "# evaluate the model\n",
        "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test Accuracy: %.3f' % acc)\n",
        "# make a prediction\n",
        "row = [1,0,0.99539,-0.05889,0.85243,0.02306,0.83398,-0.37708,1,0.03760,0.85243,-0.17755,0.59755,-0.44945,0.60536,-0.38223,0.84356,-0.38542,0.58212,-0.32192,0.56971,-0.29674,0.36946,-0.47357,0.56811,-0.51171,0.41078,-0.46168,0.21266,-0.34090,0.42267,-0.54487,0.18641,-0.45300]\n",
        "yhat = model.predict([row])\n",
        "print('Predicted: %.3f' % yhat)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h44ezPSidp0v",
        "outputId": "a4e6ee73-a0f9-4196-8b35-f0148abc6e3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(235, 34) (116, 34) (235,) (116,)\n",
            "Test Accuracy: 0.940\n",
            "Predicted: 0.984\n"
          ]
        }
      ]
    }
  ]
}